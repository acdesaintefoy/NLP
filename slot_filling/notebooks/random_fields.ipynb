{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and list data-bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, numpy as np, pycrfsuite\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions and list data-bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rf_utils import alternative_data_base, extract_features, get_entities, extract_words_from_X\n",
    "dbs_path = f'{module_path}/query_dbs/'\n",
    "models_path = f'{module_path}/models/'\n",
    "list_files = os.listdir(dbs_path)\n",
    "list_query_type = [file_name.replace('.json','') for file_name in list_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class that load the data-base, train a model, and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFields:\n",
    "    def __init__(self, type_of_query):\n",
    "        self.type_of_query = type_of_query\n",
    "        self.model_file_path = f'{models_path}{self.type_of_query}.model'\n",
    "    \n",
    "    def drop_duplicates(self):\n",
    "        temp = [json.dumps(liste) for liste in self.alternative_data_with_duplicates]\n",
    "        temp = list(set(temp))\n",
    "        temp = [json.loads(liste) for liste in temp]\n",
    "        self.alternative_data = temp\n",
    "        \n",
    "    def load_db(self,index):\n",
    "        data = json.load(open(dbs_path  + self.type_of_query+ '.json'))[self.type_of_query]\n",
    "        self.alternative_data_with_duplicates = alternative_data_base(data)\n",
    "        self.drop_duplicates()\n",
    "        X = [extract_features(query) for query in self.alternative_data]\n",
    "        y = [get_entities(query) for query in self.alternative_data]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2)\n",
    "        if index == 0:\n",
    "            print(f'For the type of query : {type_of_query} \\n')\n",
    "            print(\"Raw data looks like : \")\n",
    "            pprint(data[0])\n",
    "            print(f\"\\n Alternative data looks like :\")\n",
    "            pprint(self.alternative_data[0])\n",
    "            print('\\n Data to feed the algorithm looks like : ')\n",
    "            pprint(X[0])\n",
    "            \n",
    "    def train_model(self,l1_penalty=0.1,l2_penalty=0.01,max_iterations=200):\n",
    "        trainer = pycrfsuite.Trainer(verbose=True)\n",
    "        for xseq, yseq in zip(self.X_train, self.y_train):\n",
    "            trainer.append(xseq, yseq)\n",
    "        trainer.set_params({'c1': l1_penalty,\n",
    "                            'c2': l2_penalty,\n",
    "                            'max_iterations': max_iterations\n",
    "                            })\n",
    "        trainer.train(self.model_file_path)\n",
    "    def pred(self):\n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(self.model_file_path)\n",
    "        self.y_pred = [tagger.tag(xseq) for xseq in self.X_test] \n",
    "        self.correspondance = [(extract_words_from_X(xseq),yseq,tagger.tag(xseq)) for xseq, yseq in zip(self.X_test,self.y_test)]\n",
    "        \n",
    "    def test_sample(self):\n",
    "        self.pred()\n",
    "        i = 23\n",
    "        for x, y in zip(self.y_pred[i], [x[1].split(\"=\")[1] for x in self.X_test[i]]):\n",
    "            print(\"%s (%s)\" % (y, x))\n",
    "    \n",
    "    def accuracy_report(self):\n",
    "        self.pred()\n",
    "        # Convert the sequences of tags into a 1-dimensional array\n",
    "        self.predictions = np.array([tag for row in self.y_pred for tag in row])\n",
    "        self.truths = np.array([tag for row in self.y_test for tag in row])\n",
    "        print(classification_report(\n",
    "            self.truths, self.predictions\n",
    "             ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save a model for each type of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the type of query : PlayMusic \n",
      "\n",
      "Raw data looks like : \n",
      "{'data': [{'text': 'I need to hear the '},\n",
      "          {'entity': 'music_item', 'text': 'song'},\n",
      "          {'text': ' '},\n",
      "          {'entity': 'track', 'text': 'Aspro Mavro'},\n",
      "          {'text': ' from '},\n",
      "          {'entity': 'artist', 'text': 'Bill Szymczyk'},\n",
      "          {'text': ' on '},\n",
      "          {'entity': 'service', 'text': 'Youtube'}]}\n",
      "\n",
      " Alternative data looks like :\n",
      "[{'entity': 'None', 'text': 'Play'},\n",
      " {'entity': 'None', 'text': 'the'},\n",
      " {'entity': 'sort', 'text': 'greatest'},\n",
      " {'entity': 'music_item', 'text': 'soundtrack'},\n",
      " {'entity': 'None', 'text': 'by'},\n",
      " {'entity': 'artist', 'text': 'Nhat'},\n",
      " {'entity': 'artist', 'text': 'Son'},\n",
      " {'entity': 'None', 'text': 'on'},\n",
      " {'entity': 'service', 'text': 'Last'},\n",
      " {'entity': 'service', 'text': 'Fm'}]\n",
      "\n",
      " Data to feed the algorithm looks like : \n",
      "[['bias',\n",
      "  'word.lower=play',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=True',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=0',\n",
      "  'len_query=10',\n",
      "  'BOS',\n",
      "  '+1:word.lower=the',\n",
      "  '+1:word.istitle=False',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=the',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=False',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=1',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=play',\n",
      "  '-1:word.istitle=True',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=greatest',\n",
      "  '+1:word.istitle=False',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=greatest',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=False',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=2',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=the',\n",
      "  '-1:word.istitle=False',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=soundtrack',\n",
      "  '+1:word.istitle=False',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=soundtrack',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=False',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=3',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=greatest',\n",
      "  '-1:word.istitle=False',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=by',\n",
      "  '+1:word.istitle=False',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=by',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=False',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=4',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=soundtrack',\n",
      "  '-1:word.istitle=False',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=nhat',\n",
      "  '+1:word.istitle=True',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=nhat',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=True',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=5',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=by',\n",
      "  '-1:word.istitle=False',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=son',\n",
      "  '+1:word.istitle=True',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=son',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=True',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=6',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=nhat',\n",
      "  '-1:word.istitle=True',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=on',\n",
      "  '+1:word.istitle=False',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=on',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=False',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=7',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=son',\n",
      "  '-1:word.istitle=True',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=last',\n",
      "  '+1:word.istitle=True',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=last',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=True',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=8',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=on',\n",
      "  '-1:word.istitle=False',\n",
      "  '-1:word.isdigit=False',\n",
      "  '+1:word.lower=fm',\n",
      "  '+1:word.istitle=True',\n",
      "  '+1:word.isdigit=False'],\n",
      " ['bias',\n",
      "  'word.lower=fm',\n",
      "  'word.isupper=False',\n",
      "  'word.istitle=True',\n",
      "  'word.isdigit=False',\n",
      "  'place_in_query=9',\n",
      "  'len_query=10',\n",
      "  '-1:word.lower=last',\n",
      "  '-1:word.istitle=True',\n",
      "  '-1:word.isdigit=False']]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       None       1.00      1.00      1.00      1505\n",
      "      album       1.00      0.87      0.93       119\n",
      "     artist       0.99      1.00      1.00       492\n",
      "      genre       0.92      1.00      0.96        34\n",
      " music_item       0.99      1.00      1.00       176\n",
      "   playlist       0.92      0.98      0.95        62\n",
      "    service       1.00      1.00      1.00       188\n",
      "       sort       0.99      1.00      0.99        76\n",
      "      track       0.94      0.99      0.96       121\n",
      "       year       1.00      0.99      1.00       142\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2915\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                  None       1.00      1.00      1.00      2822\n",
      "                  city       0.96      1.00      0.98       151\n",
      "               country       0.96      0.99      0.98       107\n",
      "               cuisine       0.98      0.98      0.98        44\n",
      "              facility       1.00      1.00      1.00        43\n",
      "party_size_description       0.98      1.00      0.99       248\n",
      "     party_size_number       1.00      1.00      1.00       209\n",
      "                   poi       0.99      0.90      0.94        78\n",
      "       restaurant_name       1.00      0.99      1.00       160\n",
      "       restaurant_type       1.00      1.00      1.00       320\n",
      "           served_dish       0.96      0.96      0.96        91\n",
      "                  sort       1.00      1.00      1.00        55\n",
      "      spatial_relation       1.00      1.00      1.00       129\n",
      "                 state       1.00      1.00      1.00       130\n",
      "             timeRange       0.99      1.00      1.00       352\n",
      "\n",
      "           avg / total       0.99      0.99      0.99      4939\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/francois/Documents/Python_files/NLP/slot_filling/query_dbs/.DS_Store.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03efd738d2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_query\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_query_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrandom_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrandom_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#random_fields.train_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8b49f6ed488f>\u001b[0m in \u001b[0;36mload_db\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbs_path\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_of_query\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_of_query\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malternative_data_with_duplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malternative_data_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/francois/Documents/Python_files/NLP/slot_filling/query_dbs/.DS_Store.json'"
     ]
    }
   ],
   "source": [
    "for index, type_of_query in enumerate(list_query_type):\n",
    "    random_fields = RandomFields(type_of_query)\n",
    "    random_fields.load_db(index=index)\n",
    "    #random_fields.train_model()\n",
    "    random_fields.accuracy_report()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       None       1.00      1.00      1.00      1532\n",
      "      album       0.95      0.87      0.91       125\n",
      "     artist       0.99      1.00      0.99       508\n",
      "      genre       0.97      0.89      0.93        38\n",
      " music_item       1.00      1.00      1.00       174\n",
      "   playlist       0.92      0.95      0.94        63\n",
      "    service       1.00      1.00      1.00       168\n",
      "       sort       1.00      1.00      1.00        96\n",
      "      track       0.93      0.97      0.95       117\n",
      "       year       1.00      1.00      1.00       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2958\n",
      "\n",
      "play (None)\n",
      "the (None)\n",
      "newest (sort)\n",
      "chant (music_item)\n",
      "by (None)\n",
      "john (artist)\n",
      "doyle (artist)\n",
      "on (None)\n",
      "zvooq (service)\n"
     ]
    }
   ],
   "source": [
    "random_fields = RandomFields(\"PlayMusic\")\n",
    "random_fields.load_db(index=index)\n",
    "random_fields.accuracy_report()\n",
    "random_fields.test_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          None       1.00      0.99      1.00      1529\n",
      "        artist       0.98      0.96      0.97       314\n",
      "   entity_name       0.95      0.93      0.94       362\n",
      "    music_item       1.00      1.00      1.00       192\n",
      "      playlist       0.97      0.99      0.98      1092\n",
      "playlist_owner       1.00      1.00      1.00       225\n",
      "\n",
      "   avg / total       0.98      0.98      0.98      3714\n",
      "\n",
      "add (None)\n",
      "this (None)\n",
      "album (music_item)\n",
      "to (None)\n",
      "digster (playlist)\n",
      "future (playlist)\n",
      "hits (playlist)\n"
     ]
    }
   ],
   "source": [
    "random_fields = RandomFields(\"AddToPlaylist\")\n",
    "random_fields.load_db(index=index)\n",
    "random_fields.accuracy_report()\n",
    "random_fields.test_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      None       1.00      1.00      1.00     12616\n",
      "                     album       0.96      0.76      0.84       115\n",
      "                    artist       0.97      0.99      0.98       793\n",
      "               best_rating       0.99      1.00      1.00       200\n",
      "                      city       0.98      0.98      0.98       406\n",
      "     condition_description       1.00      1.00      1.00        86\n",
      "     condition_temperature       1.00      1.00      1.00       123\n",
      "                   country       0.99      0.99      0.99       233\n",
      "                   cuisine       0.98      0.98      0.98        61\n",
      "          current_location       1.00      1.00      1.00        85\n",
      "               entity_name       0.98      0.94      0.96       386\n",
      "                  facility       1.00      1.00      1.00        34\n",
      "                     genre       1.00      1.00      1.00        34\n",
      "            geographic_poi       1.00      0.99      0.99       235\n",
      "             location_name       1.00      1.00      1.00       288\n",
      "                movie_name       0.95      0.96      0.96       530\n",
      "                movie_type       1.00      1.00      1.00       187\n",
      "                music_item       0.99      0.99      0.99       361\n",
      "      object_location_type       1.00      1.00      1.00       143\n",
      "               object_name       0.98      0.99      0.99      2486\n",
      "object_part_of_series_type       0.98      1.00      0.99        61\n",
      "             object_select       0.98      0.99      0.99       189\n",
      "               object_type       0.99      0.99      0.99       862\n",
      "    party_size_description       0.98      1.00      0.99       246\n",
      "         party_size_number       0.99      0.98      0.98       211\n",
      "                  playlist       0.98      0.98      0.98      1111\n",
      "            playlist_owner       1.00      1.00      1.00       223\n",
      "                       poi       1.00      0.91      0.96        70\n",
      "               rating_unit       1.00      1.00      1.00       226\n",
      "              rating_value       0.99      1.00      0.99       399\n",
      "           restaurant_name       0.98      0.96      0.97       170\n",
      "           restaurant_type       0.99      1.00      0.99       318\n",
      "               served_dish       0.99      0.87      0.92        77\n",
      "                   service       1.00      1.00      1.00       191\n",
      "                      sort       1.00      0.99      1.00       133\n",
      "          spatial_relation       0.99      1.00      1.00       431\n",
      "                     state       0.98      0.99      0.99       257\n",
      "                 timeRange       0.99      0.99      0.99      1014\n",
      "                     track       0.92      0.89      0.91       131\n",
      "                      year       1.00      1.00      1.00       148\n",
      "\n",
      "               avg / total       0.99      0.99      0.99     25870\n",
      "\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      None       1.00      1.00      1.00     12616\n",
      "                     album       0.96      0.76      0.84       115\n",
      "                    artist       0.97      0.99      0.98       793\n",
      "               best_rating       0.99      1.00      1.00       200\n",
      "                      city       0.98      0.98      0.98       406\n",
      "     condition_description       1.00      1.00      1.00        86\n",
      "     condition_temperature       1.00      1.00      1.00       123\n",
      "                   country       0.99      0.99      0.99       233\n",
      "                   cuisine       0.98      0.98      0.98        61\n",
      "          current_location       1.00      1.00      1.00        85\n",
      "               entity_name       0.98      0.94      0.96       386\n",
      "                  facility       1.00      1.00      1.00        34\n",
      "                     genre       1.00      1.00      1.00        34\n",
      "            geographic_poi       1.00      0.99      0.99       235\n",
      "             location_name       1.00      1.00      1.00       288\n",
      "                movie_name       0.95      0.96      0.96       530\n",
      "                movie_type       1.00      1.00      1.00       187\n",
      "                music_item       0.99      0.99      0.99       361\n",
      "      object_location_type       1.00      1.00      1.00       143\n",
      "               object_name       0.98      0.99      0.99      2486\n",
      "object_part_of_series_type       0.98      1.00      0.99        61\n",
      "             object_select       0.98      0.99      0.99       189\n",
      "               object_type       0.99      0.99      0.99       862\n",
      "    party_size_description       0.98      1.00      0.99       246\n",
      "         party_size_number       0.99      0.98      0.98       211\n",
      "                  playlist       0.98      0.98      0.98      1111\n",
      "            playlist_owner       1.00      1.00      1.00       223\n",
      "                       poi       1.00      0.91      0.96        70\n",
      "               rating_unit       1.00      1.00      1.00       226\n",
      "              rating_value       0.99      1.00      0.99       399\n",
      "           restaurant_name       0.98      0.96      0.97       170\n",
      "           restaurant_type       0.99      1.00      0.99       318\n",
      "               served_dish       0.99      0.87      0.92        77\n",
      "                   service       1.00      1.00      1.00       191\n",
      "                      sort       1.00      0.99      1.00       133\n",
      "          spatial_relation       0.99      1.00      1.00       431\n",
      "                     state       0.98      0.99      0.99       257\n",
      "                 timeRange       0.99      0.99      0.99      1014\n",
      "                     track       0.92      0.89      0.91       131\n",
      "                      year       1.00      1.00      1.00       148\n",
      "\n",
      "               avg / total       0.99      0.99      0.99     25870\n",
      "\n",
      "put (None)\n",
      "this (None)\n",
      "album (music_item)\n",
      "on (None)\n",
      "totally (playlist)\n",
      "alternative (playlist)\n"
     ]
    }
   ],
   "source": [
    "random_fields = RandomFields(\"AllQueries\")\n",
    "random_fields.load_db(index=index)\n",
    "random_fields.accuracy_report()\n",
    "random_fields.test_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etudes des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_fields.correspondance[0]\n",
    "future_df = []\n",
    "for query_id, query in enumerate(random_fields.correspondance):\n",
    "    sentence = query[0]\n",
    "    truths = query[1]\n",
    "    predictions = query[2]\n",
    "    for word, truth_entity, entity_pred in zip(sentence,truths, predictions):\n",
    "        row={}\n",
    "        row ={\"query_id\":query_id, \"word\":word, \"truth_entity\":truth_entity,\"entity_pred\":entity_pred}\n",
    "        future_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(future_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[\"algo_is_not_right\"] = new.apply(lambda row : row[\"truth_entity\"]!=row[\"entity_pred\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_error_in_query\n",
       "0.0     2736\n",
       "1.0       65\n",
       "2.0       22\n",
       "3.0       19\n",
       "4.0        6\n",
       "5.0        5\n",
       "6.0        4\n",
       "8.0        1\n",
       "16.0       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.groupby('query_id')[\"algo_is_not_right\"].sum().reset_index(name=\"nb_error_in_query\").groupby('nb_error_in_query').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Combinaison des deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open(dbs_path  + 'AllQueriesNoDuplicates.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from utils.classif_model import predict\n",
    "import numpy as np\n",
    "\n",
    "test = [\"\", \"I want to listen to techno music\", \"Rate Harry Potter movie zero of 6 \", \n",
    "        \"What will the weather be like tomorow mother fucker ?\", 'I want to book a table for six']\n",
    "test = np.array(test)\n",
    "predictions  = predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SearchCreativeWork', 'PlayMusic', 'RateBook', 'GetWeather', 'BookRestaurant']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
